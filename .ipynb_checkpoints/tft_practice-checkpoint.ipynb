{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94a12216-b764-4f33-a2fa-295a134aabd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # avoid printing out absolute paths\n",
    "\n",
    "import copy\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torch\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7543dba6-7607-41f2-8ba1-8413e7ea1cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install tensorflow-estimator=2.1.0\n",
    "#!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a96187ae-648a-46a4-a7f0-ad41c0467dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting.data.examples import get_stallion_data\n",
    "\n",
    "data = get_stallion_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c23a4ea-4694-4086-836d-f1de708e02bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agency</th>\n",
       "      <th>sku</th>\n",
       "      <th>volume</th>\n",
       "      <th>date</th>\n",
       "      <th>industry_volume</th>\n",
       "      <th>soda_volume</th>\n",
       "      <th>avg_max_temp</th>\n",
       "      <th>price_regular</th>\n",
       "      <th>price_actual</th>\n",
       "      <th>discount</th>\n",
       "      <th>...</th>\n",
       "      <th>football_gold_cup</th>\n",
       "      <th>beer_capital</th>\n",
       "      <th>music_fest</th>\n",
       "      <th>discount_in_percent</th>\n",
       "      <th>timeseries</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>month</th>\n",
       "      <th>log_volume</th>\n",
       "      <th>avg_volume_by_sku</th>\n",
       "      <th>avg_volume_by_agency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>Agency_25</td>\n",
       "      <td>SKU_03</td>\n",
       "      <td>0.5076</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>492612703</td>\n",
       "      <td>718394219</td>\n",
       "      <td>25.845238</td>\n",
       "      <td>1264.162234</td>\n",
       "      <td>1152.473405</td>\n",
       "      <td>111.688829</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>8.835008</td>\n",
       "      <td>228</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.678062</td>\n",
       "      <td>1225.306376</td>\n",
       "      <td>99.650400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>Agency_29</td>\n",
       "      <td>SKU_02</td>\n",
       "      <td>8.7480</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>498567142</td>\n",
       "      <td>762225057</td>\n",
       "      <td>27.584615</td>\n",
       "      <td>1316.098485</td>\n",
       "      <td>1296.804924</td>\n",
       "      <td>19.293561</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1.465966</td>\n",
       "      <td>177</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2.168825</td>\n",
       "      <td>1634.434615</td>\n",
       "      <td>11.397086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19532</th>\n",
       "      <td>Agency_47</td>\n",
       "      <td>SKU_01</td>\n",
       "      <td>4.9680</td>\n",
       "      <td>2013-09-01</td>\n",
       "      <td>454252482</td>\n",
       "      <td>789624076</td>\n",
       "      <td>30.665957</td>\n",
       "      <td>1269.250000</td>\n",
       "      <td>1266.490490</td>\n",
       "      <td>2.759510</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.217413</td>\n",
       "      <td>322</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>1.603017</td>\n",
       "      <td>2625.472644</td>\n",
       "      <td>48.295650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>Agency_53</td>\n",
       "      <td>SKU_07</td>\n",
       "      <td>21.6825</td>\n",
       "      <td>2013-10-01</td>\n",
       "      <td>480693900</td>\n",
       "      <td>791658684</td>\n",
       "      <td>29.197727</td>\n",
       "      <td>1193.842373</td>\n",
       "      <td>1128.124395</td>\n",
       "      <td>65.717978</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>beer_capital</td>\n",
       "      <td>-</td>\n",
       "      <td>5.504745</td>\n",
       "      <td>240</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>3.076505</td>\n",
       "      <td>38.529107</td>\n",
       "      <td>2511.035175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9755</th>\n",
       "      <td>Agency_17</td>\n",
       "      <td>SKU_02</td>\n",
       "      <td>960.5520</td>\n",
       "      <td>2015-03-01</td>\n",
       "      <td>515468092</td>\n",
       "      <td>871204688</td>\n",
       "      <td>23.608120</td>\n",
       "      <td>1338.334248</td>\n",
       "      <td>1232.128069</td>\n",
       "      <td>106.206179</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>music_fest</td>\n",
       "      <td>7.935699</td>\n",
       "      <td>259</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>6.867508</td>\n",
       "      <td>2143.677462</td>\n",
       "      <td>396.022140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7561</th>\n",
       "      <td>Agency_05</td>\n",
       "      <td>SKU_03</td>\n",
       "      <td>1184.6535</td>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>425528909</td>\n",
       "      <td>734443953</td>\n",
       "      <td>28.668254</td>\n",
       "      <td>1369.556376</td>\n",
       "      <td>1161.135214</td>\n",
       "      <td>208.421162</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>15.218151</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>7.077206</td>\n",
       "      <td>1566.643589</td>\n",
       "      <td>1881.866367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19204</th>\n",
       "      <td>Agency_11</td>\n",
       "      <td>SKU_05</td>\n",
       "      <td>5.5593</td>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>623319783</td>\n",
       "      <td>1049868815</td>\n",
       "      <td>31.915385</td>\n",
       "      <td>1922.486644</td>\n",
       "      <td>1651.307674</td>\n",
       "      <td>271.178970</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>14.105636</td>\n",
       "      <td>17</td>\n",
       "      <td>55</td>\n",
       "      <td>8</td>\n",
       "      <td>1.715472</td>\n",
       "      <td>1385.225478</td>\n",
       "      <td>109.699200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8781</th>\n",
       "      <td>Agency_48</td>\n",
       "      <td>SKU_04</td>\n",
       "      <td>4275.1605</td>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>509281531</td>\n",
       "      <td>892192092</td>\n",
       "      <td>26.767857</td>\n",
       "      <td>1761.258209</td>\n",
       "      <td>1546.059670</td>\n",
       "      <td>215.198539</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>music_fest</td>\n",
       "      <td>12.218455</td>\n",
       "      <td>151</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8.360577</td>\n",
       "      <td>1757.950603</td>\n",
       "      <td>1925.272108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2540</th>\n",
       "      <td>Agency_07</td>\n",
       "      <td>SKU_21</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>544203593</td>\n",
       "      <td>761469815</td>\n",
       "      <td>28.987755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>300</td>\n",
       "      <td>33</td>\n",
       "      <td>10</td>\n",
       "      <td>-18.420681</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2418.719550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12084</th>\n",
       "      <td>Agency_21</td>\n",
       "      <td>SKU_03</td>\n",
       "      <td>46.3608</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>589969396</td>\n",
       "      <td>940912941</td>\n",
       "      <td>32.478910</td>\n",
       "      <td>1675.922116</td>\n",
       "      <td>1413.571789</td>\n",
       "      <td>262.350327</td>\n",
       "      <td>...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>15.654088</td>\n",
       "      <td>181</td>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "      <td>3.836454</td>\n",
       "      <td>2034.293024</td>\n",
       "      <td>109.381800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          agency     sku     volume       date  industry_volume  soda_volume  \\\n",
       "291    Agency_25  SKU_03     0.5076 2013-01-01        492612703    718394219   \n",
       "871    Agency_29  SKU_02     8.7480 2015-01-01        498567142    762225057   \n",
       "19532  Agency_47  SKU_01     4.9680 2013-09-01        454252482    789624076   \n",
       "2089   Agency_53  SKU_07    21.6825 2013-10-01        480693900    791658684   \n",
       "9755   Agency_17  SKU_02   960.5520 2015-03-01        515468092    871204688   \n",
       "7561   Agency_05  SKU_03  1184.6535 2014-02-01        425528909    734443953   \n",
       "19204  Agency_11  SKU_05     5.5593 2017-08-01        623319783   1049868815   \n",
       "8781   Agency_48  SKU_04  4275.1605 2013-03-01        509281531    892192092   \n",
       "2540   Agency_07  SKU_21     0.0000 2015-10-01        544203593    761469815   \n",
       "12084  Agency_21  SKU_03    46.3608 2017-04-01        589969396    940912941   \n",
       "\n",
       "       avg_max_temp  price_regular  price_actual    discount  ...  \\\n",
       "291       25.845238    1264.162234   1152.473405  111.688829  ...   \n",
       "871       27.584615    1316.098485   1296.804924   19.293561  ...   \n",
       "19532     30.665957    1269.250000   1266.490490    2.759510  ...   \n",
       "2089      29.197727    1193.842373   1128.124395   65.717978  ...   \n",
       "9755      23.608120    1338.334248   1232.128069  106.206179  ...   \n",
       "7561      28.668254    1369.556376   1161.135214  208.421162  ...   \n",
       "19204     31.915385    1922.486644   1651.307674  271.178970  ...   \n",
       "8781      26.767857    1761.258209   1546.059670  215.198539  ...   \n",
       "2540      28.987755       0.000000      0.000000    0.000000  ...   \n",
       "12084     32.478910    1675.922116   1413.571789  262.350327  ...   \n",
       "\n",
       "       football_gold_cup  beer_capital  music_fest discount_in_percent  \\\n",
       "291                    -             -           -            8.835008   \n",
       "871                    -             -           -            1.465966   \n",
       "19532                  -             -           -            0.217413   \n",
       "2089                   -  beer_capital           -            5.504745   \n",
       "9755                   -             -  music_fest            7.935699   \n",
       "7561                   -             -           -           15.218151   \n",
       "19204                  -             -           -           14.105636   \n",
       "8781                   -             -  music_fest           12.218455   \n",
       "2540                   -             -           -            0.000000   \n",
       "12084                  -             -           -           15.654088   \n",
       "\n",
       "      timeseries time_idx month log_volume avg_volume_by_sku  \\\n",
       "291          228        0     1  -0.678062       1225.306376   \n",
       "871          177       24     1   2.168825       1634.434615   \n",
       "19532        322        8     9   1.603017       2625.472644   \n",
       "2089         240        9    10   3.076505         38.529107   \n",
       "9755         259       26     3   6.867508       2143.677462   \n",
       "7561          21       13     2   7.077206       1566.643589   \n",
       "19204         17       55     8   1.715472       1385.225478   \n",
       "8781         151        2     3   8.360577       1757.950603   \n",
       "2540         300       33    10 -18.420681          0.000000   \n",
       "12084        181       51     4   3.836454       2034.293024   \n",
       "\n",
       "      avg_volume_by_agency  \n",
       "291              99.650400  \n",
       "871              11.397086  \n",
       "19532            48.295650  \n",
       "2089           2511.035175  \n",
       "9755            396.022140  \n",
       "7561           1881.866367  \n",
       "19204           109.699200  \n",
       "8781           1925.272108  \n",
       "2540           2418.719550  \n",
       "12084           109.381800  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_forecasting.data.examples import get_stallion_data\n",
    "\n",
    "data = get_stallion_data()\n",
    "\n",
    "# add time index\n",
    "data[\"time_idx\"] = data[\"date\"].dt.year * 12 + data[\"date\"].dt.month\n",
    "data[\"time_idx\"] -= data[\"time_idx\"].min()\n",
    "\n",
    "# add additional features\n",
    "data[\"month\"] = data.date.dt.month.astype(str).astype(\"category\")  # categories have be strings\n",
    "data[\"log_volume\"] = np.log(data.volume + 1e-8)\n",
    "data[\"avg_volume_by_sku\"] = data.groupby([\"time_idx\", \"sku\"], observed=True).volume.transform(\"mean\")\n",
    "data[\"avg_volume_by_agency\"] = data.groupby([\"time_idx\", \"agency\"], observed=True).volume.transform(\"mean\")\n",
    "\n",
    "# we want to encode special days as one variable and thus need to first reverse one-hot encoding\n",
    "special_days = [\n",
    "    \"easter_day\",\n",
    "    \"good_friday\",\n",
    "    \"new_year\",\n",
    "    \"christmas\",\n",
    "    \"labor_day\",\n",
    "    \"independence_day\",\n",
    "    \"revolution_day_memorial\",\n",
    "    \"regional_games\",\n",
    "    \"fifa_u_17_world_cup\",\n",
    "    \"football_gold_cup\",\n",
    "    \"beer_capital\",\n",
    "    \"music_fest\",\n",
    "]\n",
    "data[special_days] = data[special_days].apply(lambda x: x.map({0: \"-\", 1: x.name})).astype(\"category\")\n",
    "data.sample(10, random_state=521)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9faebf7-151f-4d10-bed4-4b514654d4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prediction_length = 6\n",
    "max_encoder_length = 24\n",
    "training_cutoff = data['time_idx'].max() - max_prediction_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "593c2c8d-402c-48cc-bae9-fce722c359ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = TimeSeriesDataSet(\n",
    "    data[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"volume\",\n",
    "    group_ids=[\"agency\", \"sku\"],\n",
    "    min_encoder_length=max_encoder_length // 2,  # keep encoder length long (as it is in the validation set)\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[\"agency\", \"sku\"],\n",
    "    static_reals=[\"avg_population_2017\", \"avg_yearly_household_income_2017\"],\n",
    "    time_varying_known_categoricals=[\"special_days\", \"month\"],\n",
    "    variable_groups={\"special_days\": special_days},  # group of categorical variables can be treated as one variable\n",
    "    time_varying_known_reals=[\"time_idx\", \"price_regular\", \"discount_in_percent\"],\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    time_varying_unknown_reals=[\n",
    "        \"volume\",\n",
    "        \"log_volume\",\n",
    "        \"industry_volume\",\n",
    "        \"soda_volume\",\n",
    "        \"avg_max_temp\",\n",
    "        \"avg_volume_by_agency\",\n",
    "        \"avg_volume_by_sku\",\n",
    "    ],\n",
    "    target_normalizer=GroupNormalizer(\n",
    "        groups=[\"agency\", \"sku\"], transformation=\"softplus\"\n",
    "    ),  # use softplus and normalize by group\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    ")\n",
    "\n",
    "# create validation set (predict=True) which means to predict the last max_prediction_length points in time\n",
    "# for each series\n",
    "validation = TimeSeriesDataSet.from_dataset(training, data, predict=True, stop_randomization=True)\n",
    "\n",
    "# create dataloaders for model\n",
    "batch_size = 128  # set this between 32 to 128\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "488bcf6c-2e1b-4f16-82ff-fb52ade4ed94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 29.7k\n"
     ]
    }
   ],
   "source": [
    "# configure network and trainer\n",
    "pl.seed_everything(42)\n",
    "trainer = pl.Trainer(\n",
    "    gpus=0,\n",
    "    # clipping gradients is a hyperparameter and important to prevent divergance\n",
    "    # of the gradient for recurrent neural networks\n",
    "    gradient_clip_val=0.1,\n",
    ")\n",
    "\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    # not meaningful for finding the learning rate but otherwise very important\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,  # most important hyperparameter apart from learning rate\n",
    "    # number of attention heads. Set to up to 4 for large datasets\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,  # between 0.1 and 0.3 are good values\n",
    "    hidden_continuous_size=8,  # set to <= hidden_size\n",
    "    output_size=7,  # 7 quantiles by default\n",
    "    loss=QuantileLoss(),\n",
    "    # reduce learning rate if no improvement in validation loss after x epochs\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79da45de-1960-4824-809e-0c8512a9cf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b7ec69ff0804b0c9ea70694f30a1dfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at C:\\Users\\LDCC\\Desktop\\eco_code\\automl_forecast\\lr_find_temp_model_a7930228-2e9d-47fb-9e57-34c5f9504713.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suggested learning rate: 5.888436553555889e-06\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# find optimal learning rate\n",
    "res = trainer.tuner.lr_find(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    "    max_lr=10.0,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "fig = res.plot(show=True, suggest=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d45aa4e-6638-440d-8e32-a8f8a3d95136",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 29.7k\n"
     ]
    }
   ],
   "source": [
    "# configure network and trainer\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=30,\n",
    "    gpus=0,\n",
    "    enable_model_summary=True,\n",
    "    gradient_clip_val=0.1,\n",
    "    limit_train_batches=30,  # coment in for training, running valiation every 30 batches\n",
    "    # fast_dev_run=True,  # comment in to check that networkor dataset has no serious bugs\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=8,\n",
    "    output_size=7,  # 7 quantiles by default\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=10,  # uncomment for learning rate finder and otherwise, e.g. to 10 for logging every 10 batches\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71233073-093c-4032-97f6-fe67f4c5881c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name                               | Type                            | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0     \n",
      "1  | logging_metrics                    | ModuleList                      | 0     \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 1.3 K \n",
      "3  | prescalers                         | ModuleDict                      | 256   \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 3.4 K \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 8.0 K \n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 2.7 K \n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 1.1 K \n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 1.1 K \n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 1.1 K \n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 1.1 K \n",
      "11 | lstm_encoder                       | LSTM                            | 2.2 K \n",
      "12 | lstm_decoder                       | LSTM                            | 2.2 K \n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 544   \n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 32    \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 1.4 K \n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 1.1 K \n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 576   \n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 1.1 K \n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 576   \n",
      "20 | output_layer                       | Linear                          | 119   \n",
      "----------------------------------------------------------------------------------------\n",
      "29.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "29.7 K    Total params\n",
      "0.119     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "# fit network\n",
    "\n",
    "\n",
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e07593-7ecb-47e9-9e6b-d17789cc384d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-10 17:55:59,822]\u001b[0m A new study created in memory with name: no-name-22d29351-eb96-4bec-a86b-f988e66355c2\u001b[0m\n",
      "C:\\Users\\LDCC\\anaconda3\\envs\\practice\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\callback_connector.py:168: LightningDeprecationWarning: Setting `Trainer(weights_summary=None)` is deprecated in v1.5 and will be removed in v1.7. Please set `Trainer(enable_model_summary=False)` instead.\n",
      "  \"Setting `Trainer(weights_summary=None)` is deprecated in v1.5 and will be removed\"\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "\n",
    "# create study\n",
    "study = optimize_hyperparameters(\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    model_path=\"optuna_test\",\n",
    "    n_trials=200,\n",
    "    max_epochs=50,\n",
    "    gradient_clip_val_range=(0.01, 1.0),\n",
    "    hidden_size_range=(8, 128),\n",
    "    hidden_continuous_size_range=(8, 128),\n",
    "    attention_head_size_range=(1, 4),\n",
    "    learning_rate_range=(0.001, 0.1),\n",
    "    dropout_range=(0.1, 0.3),\n",
    "    trainer_kwargs=dict(limit_train_batches=30),\n",
    "    reduce_on_plateau_patience=4,\n",
    "    use_learning_rate_finder=False,  # use Optuna to find ideal learning rate or use in-built learning rate finder\n",
    ")\n",
    "\n",
    "# save study results - also we can resume tuning at a later point in time\n",
    "with open(\"test_study.pkl\", \"wb\") as fout:\n",
    "    pickle.dump(study, fout)\n",
    "\n",
    "# show best hyperparameters\n",
    "print(study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729ecac7-07ff-4d1f-8281-217c77d4a8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model according to the validation loss\n",
    "# (given that we use early stopping, this is not necessarily the last epoch)\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed4e1fb-8bf8-4022-aa70-f2bbabe063e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw predictions are a dictionary from which all kind of information including quantiles can be extracted\n",
    "raw_predictions, x = best_tft.predict(val_dataloader, mode=\"raw\", return_x=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6384e338-f9aa-4945-bfef-6be60b611dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select last 24 months from data (max_encoder_length is 24)\n",
    "encoder_data = data[lambda x: x.time_idx > x.time_idx.max() - max_encoder_length]\n",
    "\n",
    "# select last known data point and create decoder data from it by repeating it and incrementing the month\n",
    "# in a real world dataset, we should not just forward fill the covariates but specify them to account\n",
    "# for changes in special days and prices (which you absolutely should do but we are too lazy here)\n",
    "last_data = data[lambda x: x.time_idx == x.time_idx.max()]\n",
    "decoder_data = pd.concat(\n",
    "    [last_data.assign(date=lambda x: x.date + pd.offsets.MonthBegin(i)) for i in range(1, max_prediction_length + 1)],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "# add time index consistent with \"data\"\n",
    "decoder_data[\"time_idx\"] = decoder_data[\"date\"].dt.year * 12 + decoder_data[\"date\"].dt.month\n",
    "decoder_data[\"time_idx\"] += encoder_data[\"time_idx\"].max() + 1 - decoder_data[\"time_idx\"].min()\n",
    "\n",
    "# adjust additional time feature(s)\n",
    "decoder_data[\"month\"] = decoder_data.date.dt.month.astype(str).astype(\"category\")  # categories have be strings\n",
    "\n",
    "# combine encoder and decoder data\n",
    "new_prediction_data = pd.concat([encoder_data, decoder_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232d6d2a-02db-4e8b-9f2d-d7875fc63d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_raw_predictions, new_x = best_tft.predict(new_prediction_data, mode=\"raw\", return_x=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006e5dae-d1c2-4e86-b717-6f306458ad5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
